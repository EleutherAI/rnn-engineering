{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mamba_ssm\n",
    "from nnsight import LanguageModel, util\n",
    "from nnsight.tracing.Proxy import Proxy\n",
    "from nnsight.models.Mamba import MambaInterp\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "\n",
    "from typing import List, Callable, Union\n",
    "\n",
    "device = t.device(\"cuda:2\" if t.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\", padding_side=\"left\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "mamba_model = MambaInterp(\"state-spaces/mamba-2.8b\", device=device, tokenizer=tokenizer)\n",
    "sampling_kwargs = {\n",
    "    \"top_p\": 0.2,\n",
    "    \"top_k\": 0,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "} # in mamba_ssm/utils/generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel tower is located in Paris, France. It was built between 1889 and\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "with mamba_model.generate(\"The Eiffel tower is located\",max_length=20,scan=False, validate=False,**sampling_kwargs) as tracer:\n",
    "    output = mamba_model.generator.output.save()\n",
    "decoded = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaModuleInterp(\n",
       "  (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "  (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "  (act): SiLU()\n",
       "  (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "  (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "  (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "  (dt): WrapperModule()\n",
       "  (B): WrapperModule()\n",
       "  (C): WrapperModule()\n",
       "  (ssm): SSM(\n",
       "    (discA): DiscA()\n",
       "    (discB): DiscB()\n",
       "    (hx): Hx(\n",
       "      (bx): Bx()\n",
       "      (ah): Ah()\n",
       "    )\n",
       "    (yh): Yh()\n",
       "  )\n",
       "  (delta_softplus): Softplus(beta=1, threshold=20)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mamba_model.backbone.layers[0].mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Accessing Proxy value before it's been set.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mamba_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Eiffel tower is located\u001b[39m\u001b[38;5;124m\"\u001b[39m,max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,scan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampling_kwargs) \u001b[38;5;28;01mas\u001b[39;00m tracer:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m mamba_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m      5\u001b[0m        \u001b[38;5;66;03m#inputs.append(layer.mixer.ssm.input[0].save())\u001b[39;00m\n\u001b[1;32m      6\u001b[0m        outputs\u001b[38;5;241m.\u001b[39mappend(layer\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39mssm\u001b[38;5;241m.\u001b[39mdiscA\u001b[38;5;241m.\u001b[39msave())\n",
      "File \u001b[0;32m/mnt/ssd-1/gpaulo/miniconda3/envs/default/lib/python3.10/site-packages/nnsight/contexts/Runner.py:41\u001b[0m, in \u001b[0;36mRunner.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"On exit, run and generate using the model whether locally or on the server.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_server()\n",
      "Cell \u001b[0;32mIn[60], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mamba_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Eiffel tower is located\u001b[39m\u001b[38;5;124m\"\u001b[39m,max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,scan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampling_kwargs) \u001b[38;5;28;01mas\u001b[39;00m tracer:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m mamba_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m      5\u001b[0m        \u001b[38;5;66;03m#inputs.append(layer.mixer.ssm.input[0].save())\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m        outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m        \u001b[38;5;66;03m#pass\u001b[39;00m\n\u001b[1;32m      8\u001b[0m        \u001b[38;5;66;03m#layer.mixer.ssm.discA.output=t.ones_like(layer.mixer.ssm.discA.output)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m mamba_model\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/mnt/ssd-1/gpaulo/miniconda3/envs/default/lib/python3.10/site-packages/nnsight/intervention.py:68\u001b[0m, in \u001b[0;36mInterventionProxy.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Method when called, indicates to the intervention graph to not delete the tensor values of the result.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    InterventionProxy: Save proxy.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Add a 'null' node with the save proxy as an argument to ensure the values are never deleted.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# This is because 'null' nodes never actually get set and therefore there will always be a\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# dependency for the save proxy.\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/mnt/ssd-1/gpaulo/miniconda3/envs/default/lib/python3.10/site-packages/nnsight/tracing/Node.py:201\u001b[0m, in \u001b[0;36mNode.add\u001b[0;34m(self, target, value, args, kwargs, name)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"We use Node.add vs Graph.add in case the weakref to Graph is gone.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    Proxy: Proxy\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mProxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    204\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget, value\u001b[38;5;241m=\u001b[39mvalue, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    205\u001b[0m )\n",
      "File \u001b[0;32m/mnt/ssd-1/gpaulo/miniconda3/envs/default/lib/python3.10/site-packages/nnsight/tracing/Proxy.py:50\u001b[0m, in \u001b[0;36mProxy.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Property to return the value of this proxy's node.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Any: The stored value of the proxy, populated during execution of the model.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing Proxy value before it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mValueError\u001b[0m: Accessing Proxy value before it's been set."
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "with mamba_model.generate(\"The Eiffel tower is located\",max_length=20,scan=False, validate=False,**sampling_kwargs) as tracer:\n",
    "    for layer in mamba_model.backbone.layers:\n",
    "       #inputs.append(layer.mixer.ssm.input[0].save())\n",
    "       outputs.append(layer.mixer.ssm.discA.save())\n",
    "       #pass\n",
    "       #layer.mixer.ssm.discA.output=t.ones_like(layer.mixer.ssm.discA.output)\n",
    "      \n",
    "      \n",
    "    output = mamba_model.generator.output.save()\n",
    "\n",
    "decoded = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.9072, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "with mamba_model.invoke(dataset[\"text\"][0][:800],scan=True) as invoker:\n",
    "\n",
    "    for layer in mamba_model.backbone.layers:\n",
    "        A_bar = layer.mixer.ssm.discA.output\n",
    "        dB = layer.mixer.ssm.discB.output\n",
    "        dA = layer.mixer.ssm.dA.output\n",
    "        zohDeltaB=dB*1/dA*(A_bar-1) \n",
    "        layer.mixer.ssm.discB.output=t.zeros_like(zohDeltaB)\n",
    "        layer.mixer.ssm.discA.output=t.zeros_like(A_bar)\n",
    "\n",
    "output=invoker.output\n",
    "loss = compute_loss(dataset[\"text\"][0][:800],output.logits[0])  \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaLMHeadModel(\n",
       "  (backbone): MixerModel(\n",
       "    (embedding): Embedding(50280, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-63): 64 x Block(\n",
       "        (mixer): MambaModuleInterp(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "          (dt): WrapperModule()\n",
       "          (B): WrapperModule()\n",
       "          (C): WrapperModule()\n",
       "          (ssm): SSM(\n",
       "            (discA): DiscA()\n",
       "            (discB): DiscB()\n",
       "            (dA): DA()\n",
       "            (hx): Hx(\n",
       "              (bx): Bx()\n",
       "              (ah): Ah()\n",
       "            )\n",
       "            (yh): Yh()\n",
       "          )\n",
       "          (delta_softplus): Softplus(beta=1, threshold=20)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mamba_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.7835, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "with mamba_model.invoke(dataset[\"text\"][0][:50],scan=True) as invoker:\n",
    "\n",
    "    for layer in mamba_model.backbone.layers:\n",
    "        out = layer.mixer.conv1d.output[0][:,:]\n",
    "        layer.mixer.conv1d.output[0][...,:] = t.concat([layer.mixer.conv1d.input[0][0][0][:,:],t.zeros_like(out)[:,:3]],dim=1)  #A_bar = layer.mixer.ssm.discA.output\n",
    "        \n",
    "output=invoker.output\n",
    "loss = compute_loss(dataset[\"text\"][0][:50],output.logits[0])  \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.1457, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "with mamba_model.invoke(dataset[\"text\"][0][:50],scan=True) as invoker:\n",
    "\n",
    "    out = mamba_model.backbone.layers[0].mixer.conv1d.output[0][:,:]\n",
    "    mamba_model.backbone.layers[0].mixer.conv1d.output[0][...,:] = t.concat([mamba_model.backbone.layers[0].mixer.conv1d.input[0][0][0][:,:],t.zeros_like(out)[:,:3]],dim=1)  #A_bar = layer.mixer.ssm.discA.output\n",
    "        \n",
    "output=invoker.output\n",
    "loss = compute_loss(dataset[\"text\"][0][:50],output.logits[0])  \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(176.0256, device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "with mamba_model.invoke(dataset[\"text\"][0][:50],scan=True) as invoker:\n",
    "\n",
    "    for layer in mamba_model.backbone.layers:\n",
    "        out = layer.mixer.conv1d.output[0].save()\n",
    "        layer.mixer.conv1d.output[0]= t.zeros_like(out) \n",
    "        \n",
    "output=invoker.output\n",
    "loss = compute_loss(dataset[\"text\"][0][:50],output.logits[0])  \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 50280])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoker.output.logits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2534, -0.4671, -0.5139,  ...,  0.6724, -0.2481,  0.2129],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_input.value[0][0][0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0650,  0.0308,  0.0203,  ..., -0.0028,  0.2437, -0.0757],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_output.value[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
